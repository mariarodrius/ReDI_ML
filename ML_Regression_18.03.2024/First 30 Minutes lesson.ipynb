{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from video, first 30 min lesson:\n",
    "#########################################\n",
    "tips:\n",
    "mydatapf = pd.DataFrame(mydata)\n",
    "print(mydatapd.describe())\n",
    "\n",
    "##########################################\n",
    "\n",
    "\n",
    "print(\"first row \\n\", mydata[0,:])\n",
    "\n",
    "print(\"first column \\n\", mydata[:,1])\n",
    "\n",
    "##refresher on pyplot plt:\n",
    "\n",
    "fig = plt.fig(figsize(8,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('data stephan')\n",
    "ax.scatter(mydata[:,0], mydata[:,1])\n",
    "\n",
    "#can also do:\n",
    "\n",
    "X=mydata[:,0]\n",
    "Y=mydata[:,1]\n",
    "plt.scatter(X,Y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "### end of refresher on plt\n",
    "\n",
    "### Regression, 18.03.2024:\n",
    "##file RegressionModel_SP:\n",
    "\n",
    "m = .0008\n",
    "c = 1.68\n",
    "yhat = m*X + c\n",
    "\n",
    "plt.plot(X,yhat)\n",
    "\n",
    "\n",
    "# Minimize the sum of the squares of the distances of the data points to the regression line.\n",
    "residual = np.sum((Y-yhat)**2)\n",
    "print(\"the  residual is\", residual)\n",
    "\n",
    "SumX = np.sum(X)\n",
    "SumY = np.sum(Y)\n",
    "SumXX = np.sum(X*X)\n",
    "SumXY = np.sum(X*Y)\n",
    "N = X.size  ##number of data ppoints is the size of the array\n",
    "\n",
    "##training parameters m, b\n",
    "m = (N*SumXY-SumX*SumY)/(N*SumXX-SumX*SumX)\n",
    "c = (SumY-m*SumX)/N\n",
    "print(\"slope m = \", m, \"y axis intercept c = \", c)\n",
    "\n",
    "\n",
    "Class MLRegression:\n",
    "\tdef __init__(self):\n",
    "\t\tself.m = 0  ##defining slope\n",
    "\t\tself.c = 0  ##defining intercept\n",
    "\t\tself.N = 1  ##assigning an initial non-zero valu to the number of data points \n",
    "\t\t\t    ###as we will have to divide by N later (see b = ... above)\n",
    "\n",
    "\tdef train (self, Xtrain, Ytrain):\n",
    "\t\tself.X = Xtrain\n",
    "\t\tself.Y = Ytrain\n",
    "\t\tSumX = np.sum(self.X)\n",
    "\t\tSumY = np.sum(self.Y)\n",
    "\t\tSumXX = np.sum(self.X*self.X)\n",
    "\t\tSumXY = np.sum(self.X*self.Y)\n",
    "\n",
    "\t\tself.N = self.X.size \t\t\n",
    "\t\tself.m = (self.N*SumXY-SumX*SumY)/(self.N*SumXX-SumX*SumX)\n",
    "\t\tself.c = (SumY-self.m*SumX)/self.N\n",
    "\t\tprint(\"ML Regression Model has been trained\")\n",
    "\t\tprint(\"m=\", self.m, \"c=\", self.c\")\n",
    "\t\tplt.scatter(self.X,self.Y)\n",
    "\t\tyhat = self.m * self.X + self.c\n",
    "\t\tplt.plt(self.X, yhat, lw = 4, c= \"orange\")  ## lw = line width; c = colour\n",
    "\n",
    "\n",
    "\tdef predict (self, Xtext):\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "##file Regression_SP:\n",
    "##call for the file RegressionModel_SP:\n",
    "\n",
    "from RegressionModel_SP import MLRegresssion   ###from the file, import the class (or function) MLRegression\n",
    "regression = MLRegression()\t\t\t###open an object of type MLRegression class\n",
    "regression.train(X,Y)\t\t\t\t###call the function train (def train) \n",
    "\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "#using linalg from numpy to calculate least square regression\n",
    "\n",
    "A = np.vstack([X,np.ones(len(X))]).T  ## stacks the x values from the data in a transposed matrix \n",
    "\t\t\t\t\t###(in float form though), \n",
    "\t\t\t\t\t###so they become a column, and adds ones as column 2\n",
    "\n",
    "A\n",
    "\n",
    "\n",
    "solu = np.linalg.lstsq(A,Y,rcond=None)  ##solu is our name for the solution\n",
    "solu\n",
    "\n",
    "##let's separate the values to identify them:\n",
    "\n",
    "m, c = solu[0]\n",
    "\n",
    "## so, linalg calculates also the slope and intercept; it is just another way. and also the residual:\n",
    "\n",
    "residual = solu[1]\n",
    "residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
